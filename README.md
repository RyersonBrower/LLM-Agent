# LLM-Agent

An intelligent agent system built with Python, Flask, and Docker. The project provides an interactive web interface that communicates with a backend agent service powered by LLMs. The system is fully containerized and designed for easy expansion.

## ğŸš€ Features
- Interactive Flask-based web UI  
- Backend agent powered by OpenAI API  
- Fully containerized using Docker and docker-compose  
- Clean separation between web and agent services  
- Environment-variable configuration  
- Easy to extend with tools, memory, or additional agents  

## ğŸ“‚ Project Structure
LLM-Agent/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ script.js
â””â”€â”€ agent/
    â”œâ”€â”€ Dockerfile
    â””â”€â”€ app.py

## âš™ï¸ How It Works

### Web Service (Port 5000)
- Hosts the frontend UI  
- Sends user messages to the agent service  
- Displays results

### Agent Service (Port 5001)
- Processes messages from the web  
- Calls the LLM (e.g., OpenAI)  
- Returns JSON responses  

## ğŸ³ Running the Project

### 1. Add a `.env` file:
OPENAI_API_KEY=your_api_key_here

### 2. Build and start:
docker compose up --build

### 3. Open the app:
http://localhost:5000

## ğŸ§© Agent API

### POST /agent  
Request:
{
  "message": "Write a Python function that reverses a string."
}

Response:
{
  "response": "Here's a sample Python function..."
}

## ğŸ› ï¸ Tech Stack
- Python  
- Flask  
- Docker / Docker Compose  
- OpenAI API  
- HTML, CSS, JavaScript  

## ğŸ”§ Future Enhancements
- Memory and persistence  
- Multi-agent workflows  
- Tool/function calling  
- Authentication  
- React frontend  

## ğŸ“„ License
This project is for educational and personal use. Modify and extend as needed.
